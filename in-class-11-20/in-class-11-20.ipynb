{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6d0ad73",
   "metadata": {},
   "source": [
    "#### in class assignment `nov 20`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "09c44e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2481a911",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7d47cd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.text(\"./metamorphosis.txt\")\n",
    "# get lines as rows\n",
    "df = df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2ed3d412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all lowers\n",
    "df[\"value\"] = df[\"value\"].apply(lambda x: x.lower())\n",
    "# split lines into words\n",
    "df[\"value\"] = df[\"value\"].apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d2c5c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/20 12:05:10 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:669)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1296)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.39.39.249:63771\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/11/20 12:05:10 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:342)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:700)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:699)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:739)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@10.39.39.249:63771\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:504)\n",
      "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:335)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
      "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:429)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:338)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:285)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:278)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/11/20 12:05:10 ERROR Executor: Exit as unable to send heartbeats to driver more than 60 times\n",
      "25/11/20 12:05:20 WARN JavaUtils: Attempt to delete using native Unix OS command failed for path = /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316. Falling back to Java IO way\n",
      "java.io.IOException: Failed to delete: /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:191)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:116)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120)\n",
      "\tat org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1048)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1(DiskBlockManager.scala:372)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1$adapted(DiskBlockManager.scala:368)\n",
      "\tat scala.collection.ArrayOps$.foreach$extension(ArrayOps.scala:1324)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.doStop(DiskBlockManager.scala:368)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.stop(DiskBlockManager.scala:363)\n",
      "\tat org.apache.spark.storage.BlockManager.stop(BlockManager.scala:2166)\n",
      "\tat org.apache.spark.SparkEnv.stop(SparkEnv.scala:118)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1300)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2297)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$36(SparkContext.scala:704)\n",
      "\tat org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:231)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat scala.util.Try$.apply(Try.scala:217)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:205)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:184)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: java.io.IOException: Cannot run program \"rm\": error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1170)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1089)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:183)\n",
      "\t... 31 more\n",
      "Caused by: java.io.IOException: error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessImpl.forkAndExec(Native Method)\n",
      "\tat java.base/java.lang.ProcessImpl.<init>(ProcessImpl.java:295)\n",
      "\tat java.base/java.lang.ProcessImpl.start(ProcessImpl.java:225)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1126)\n",
      "\t... 33 more\n",
      "25/11/20 12:05:20 WARN JavaUtils: Attempt to delete using native Unix OS command failed for path = /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/0d. Falling back to Java IO way\n",
      "java.io.IOException: Failed to delete: /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/0d\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:191)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:116)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120)\n",
      "\tat org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1048)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1(DiskBlockManager.scala:372)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1$adapted(DiskBlockManager.scala:368)\n",
      "\tat scala.collection.ArrayOps$.foreach$extension(ArrayOps.scala:1324)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.doStop(DiskBlockManager.scala:368)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.stop(DiskBlockManager.scala:363)\n",
      "\tat org.apache.spark.storage.BlockManager.stop(BlockManager.scala:2166)\n",
      "\tat org.apache.spark.SparkEnv.stop(SparkEnv.scala:118)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1300)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2297)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$36(SparkContext.scala:704)\n",
      "\tat org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:231)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat scala.util.Try$.apply(Try.scala:217)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:205)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:184)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: java.io.IOException: Cannot run program \"rm\": error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1170)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1089)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:183)\n",
      "\t... 33 more\n",
      "Caused by: java.io.IOException: error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessImpl.forkAndExec(Native Method)\n",
      "\tat java.base/java.lang.ProcessImpl.<init>(ProcessImpl.java:295)\n",
      "\tat java.base/java.lang.ProcessImpl.start(ProcessImpl.java:225)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1126)\n",
      "\t... 35 more\n",
      "25/11/20 12:05:20 WARN JavaUtils: Attempt to delete using native Unix OS command failed for path = /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/0c. Falling back to Java IO way\n",
      "java.io.IOException: Failed to delete: /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/0c\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:191)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:116)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120)\n",
      "\tat org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1048)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1(DiskBlockManager.scala:372)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1$adapted(DiskBlockManager.scala:368)\n",
      "\tat scala.collection.ArrayOps$.foreach$extension(ArrayOps.scala:1324)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.doStop(DiskBlockManager.scala:368)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.stop(DiskBlockManager.scala:363)\n",
      "\tat org.apache.spark.storage.BlockManager.stop(BlockManager.scala:2166)\n",
      "\tat org.apache.spark.SparkEnv.stop(SparkEnv.scala:118)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1300)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2297)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$36(SparkContext.scala:704)\n",
      "\tat org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:231)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat scala.util.Try$.apply(Try.scala:217)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:205)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:184)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: java.io.IOException: Cannot run program \"rm\": error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1170)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1089)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:183)\n",
      "\t... 33 more\n",
      "Caused by: java.io.IOException: error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessImpl.forkAndExec(Native Method)\n",
      "\tat java.base/java.lang.ProcessImpl.<init>(ProcessImpl.java:295)\n",
      "\tat java.base/java.lang.ProcessImpl.start(ProcessImpl.java:225)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1126)\n",
      "\t... 35 more\n",
      "25/11/20 12:05:20 WARN JavaUtils: Attempt to delete using native Unix OS command failed for path = /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/0c/shuffle_0_0_0.data. Falling back to Java IO way\n",
      "java.io.IOException: Failed to delete: /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/0c/shuffle_0_0_0.data\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:191)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:116)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120)\n",
      "\tat org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1048)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1(DiskBlockManager.scala:372)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1$adapted(DiskBlockManager.scala:368)\n",
      "\tat scala.collection.ArrayOps$.foreach$extension(ArrayOps.scala:1324)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.doStop(DiskBlockManager.scala:368)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.stop(DiskBlockManager.scala:363)\n",
      "\tat org.apache.spark.storage.BlockManager.stop(BlockManager.scala:2166)\n",
      "\tat org.apache.spark.SparkEnv.stop(SparkEnv.scala:118)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1300)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2297)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$36(SparkContext.scala:704)\n",
      "\tat org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:231)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat scala.util.Try$.apply(Try.scala:217)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:205)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:184)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: java.io.IOException: Cannot run program \"rm\": error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1170)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1089)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:183)\n",
      "\t... 35 more\n",
      "Caused by: java.io.IOException: error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessImpl.forkAndExec(Native Method)\n",
      "\tat java.base/java.lang.ProcessImpl.<init>(ProcessImpl.java:295)\n",
      "\tat java.base/java.lang.ProcessImpl.start(ProcessImpl.java:225)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1126)\n",
      "\t... 37 more\n",
      "25/11/20 12:05:20 WARN JavaUtils: Attempt to delete using native Unix OS command failed for path = /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/3b. Falling back to Java IO way\n",
      "java.io.IOException: Failed to delete: /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/3b\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:191)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:116)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120)\n",
      "\tat org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1048)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1(DiskBlockManager.scala:372)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1$adapted(DiskBlockManager.scala:368)\n",
      "\tat scala.collection.ArrayOps$.foreach$extension(ArrayOps.scala:1324)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.doStop(DiskBlockManager.scala:368)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.stop(DiskBlockManager.scala:363)\n",
      "\tat org.apache.spark.storage.BlockManager.stop(BlockManager.scala:2166)\n",
      "\tat org.apache.spark.SparkEnv.stop(SparkEnv.scala:118)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1300)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2297)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$36(SparkContext.scala:704)\n",
      "\tat org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:231)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat scala.util.Try$.apply(Try.scala:217)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:205)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:184)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: java.io.IOException: Cannot run program \"rm\": error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1170)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1089)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:183)\n",
      "\t... 33 more\n",
      "Caused by: java.io.IOException: error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessImpl.forkAndExec(Native Method)\n",
      "\tat java.base/java.lang.ProcessImpl.<init>(ProcessImpl.java:295)\n",
      "\tat java.base/java.lang.ProcessImpl.start(ProcessImpl.java:225)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1126)\n",
      "\t... 35 more\n",
      "25/11/20 12:05:20 WARN JavaUtils: Attempt to delete using native Unix OS command failed for path = /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/35. Falling back to Java IO way\n",
      "java.io.IOException: Failed to delete: /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/35\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:191)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:116)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120)\n",
      "\tat org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1048)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1(DiskBlockManager.scala:372)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1$adapted(DiskBlockManager.scala:368)\n",
      "\tat scala.collection.ArrayOps$.foreach$extension(ArrayOps.scala:1324)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.doStop(DiskBlockManager.scala:368)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.stop(DiskBlockManager.scala:363)\n",
      "\tat org.apache.spark.storage.BlockManager.stop(BlockManager.scala:2166)\n",
      "\tat org.apache.spark.SparkEnv.stop(SparkEnv.scala:118)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1300)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2297)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$36(SparkContext.scala:704)\n",
      "\tat org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:231)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat scala.util.Try$.apply(Try.scala:217)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:205)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:184)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: java.io.IOException: Cannot run program \"rm\": error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1170)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1089)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:183)\n",
      "\t... 33 more\n",
      "Caused by: java.io.IOException: error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessImpl.forkAndExec(Native Method)\n",
      "\tat java.base/java.lang.ProcessImpl.<init>(ProcessImpl.java:295)\n",
      "\tat java.base/java.lang.ProcessImpl.start(ProcessImpl.java:225)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1126)\n",
      "\t... 35 more\n",
      "25/11/20 12:05:20 WARN JavaUtils: Attempt to delete using native Unix OS command failed for path = /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/35/shuffle_1_4_0.index. Falling back to Java IO way\n",
      "java.io.IOException: Failed to delete: /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/35/shuffle_1_4_0.index\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:191)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:116)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120)\n",
      "\tat org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1048)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1(DiskBlockManager.scala:372)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1$adapted(DiskBlockManager.scala:368)\n",
      "\tat scala.collection.ArrayOps$.foreach$extension(ArrayOps.scala:1324)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.doStop(DiskBlockManager.scala:368)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.stop(DiskBlockManager.scala:363)\n",
      "\tat org.apache.spark.storage.BlockManager.stop(BlockManager.scala:2166)\n",
      "\tat org.apache.spark.SparkEnv.stop(SparkEnv.scala:118)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1300)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2297)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$36(SparkContext.scala:704)\n",
      "\tat org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:231)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat scala.util.Try$.apply(Try.scala:217)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:205)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:184)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: java.io.IOException: Cannot run program \"rm\": error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1170)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1089)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:183)\n",
      "\t... 35 more\n",
      "Caused by: java.io.IOException: error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessImpl.forkAndExec(Native Method)\n",
      "\tat java.base/java.lang.ProcessImpl.<init>(ProcessImpl.java:295)\n",
      "\tat java.base/java.lang.ProcessImpl.start(ProcessImpl.java:225)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1126)\n",
      "\t... 37 more\n",
      "25/11/20 12:05:20 WARN JavaUtils: Attempt to delete using native Unix OS command failed for path = /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/3d. Falling back to Java IO way\n",
      "java.io.IOException: Failed to delete: /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/3d\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:191)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:116)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120)\n",
      "\tat org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1048)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1(DiskBlockManager.scala:372)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1$adapted(DiskBlockManager.scala:368)\n",
      "\tat scala.collection.ArrayOps$.foreach$extension(ArrayOps.scala:1324)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.doStop(DiskBlockManager.scala:368)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.stop(DiskBlockManager.scala:363)\n",
      "\tat org.apache.spark.storage.BlockManager.stop(BlockManager.scala:2166)\n",
      "\tat org.apache.spark.SparkEnv.stop(SparkEnv.scala:118)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1300)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2297)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$36(SparkContext.scala:704)\n",
      "\tat org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:231)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat scala.util.Try$.apply(Try.scala:217)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:205)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:184)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: java.io.IOException: Cannot run program \"rm\": error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1170)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1089)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:183)\n",
      "\t... 33 more\n",
      "Caused by: java.io.IOException: error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessImpl.forkAndExec(Native Method)\n",
      "\tat java.base/java.lang.ProcessImpl.<init>(ProcessImpl.java:295)\n",
      "\tat java.base/java.lang.ProcessImpl.start(ProcessImpl.java:225)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1126)\n",
      "\t... 35 more\n",
      "25/11/20 12:05:20 WARN JavaUtils: Attempt to delete using native Unix OS command failed for path = /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/0b. Falling back to Java IO way\n",
      "java.io.IOException: Failed to delete: /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/0b\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:191)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:116)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120)\n",
      "\tat org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1048)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1(DiskBlockManager.scala:372)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1$adapted(DiskBlockManager.scala:368)\n",
      "\tat scala.collection.ArrayOps$.foreach$extension(ArrayOps.scala:1324)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.doStop(DiskBlockManager.scala:368)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.stop(DiskBlockManager.scala:363)\n",
      "\tat org.apache.spark.storage.BlockManager.stop(BlockManager.scala:2166)\n",
      "\tat org.apache.spark.SparkEnv.stop(SparkEnv.scala:118)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1300)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2297)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$36(SparkContext.scala:704)\n",
      "\tat org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:231)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat scala.util.Try$.apply(Try.scala:217)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:205)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:184)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: java.io.IOException: Cannot run program \"rm\": error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1170)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1089)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:183)\n",
      "\t... 33 more\n",
      "Caused by: java.io.IOException: error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessImpl.forkAndExec(Native Method)\n",
      "\tat java.base/java.lang.ProcessImpl.<init>(ProcessImpl.java:295)\n",
      "\tat java.base/java.lang.ProcessImpl.start(ProcessImpl.java:225)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1126)\n",
      "\t... 35 more\n",
      "25/11/20 12:05:20 WARN JavaUtils: Attempt to delete using native Unix OS command failed for path = /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/0e. Falling back to Java IO way\n",
      "java.io.IOException: Failed to delete: /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/0e\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:191)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:116)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120)\n",
      "\tat org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1048)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1(DiskBlockManager.scala:372)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1$adapted(DiskBlockManager.scala:368)\n",
      "\tat scala.collection.ArrayOps$.foreach$extension(ArrayOps.scala:1324)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.doStop(DiskBlockManager.scala:368)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.stop(DiskBlockManager.scala:363)\n",
      "\tat org.apache.spark.storage.BlockManager.stop(BlockManager.scala:2166)\n",
      "\tat org.apache.spark.SparkEnv.stop(SparkEnv.scala:118)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1300)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2297)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$36(SparkContext.scala:704)\n",
      "\tat org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:231)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat scala.util.Try$.apply(Try.scala:217)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:205)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:184)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: java.io.IOException: Cannot run program \"rm\": error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1170)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1089)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:183)\n",
      "\t... 33 more\n",
      "Caused by: java.io.IOException: error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessImpl.forkAndExec(Native Method)\n",
      "\tat java.base/java.lang.ProcessImpl.<init>(ProcessImpl.java:295)\n",
      "\tat java.base/java.lang.ProcessImpl.start(ProcessImpl.java:225)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1126)\n",
      "\t... 35 more\n",
      "25/11/20 12:05:20 WARN JavaUtils: Attempt to delete using native Unix OS command failed for path = /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/34. Falling back to Java IO way\n",
      "java.io.IOException: Failed to delete: /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/34\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:191)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:116)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120)\n",
      "\tat org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1048)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1(DiskBlockManager.scala:372)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1$adapted(DiskBlockManager.scala:368)\n",
      "\tat scala.collection.ArrayOps$.foreach$extension(ArrayOps.scala:1324)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.doStop(DiskBlockManager.scala:368)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.stop(DiskBlockManager.scala:363)\n",
      "\tat org.apache.spark.storage.BlockManager.stop(BlockManager.scala:2166)\n",
      "\tat org.apache.spark.SparkEnv.stop(SparkEnv.scala:118)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1300)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2297)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$36(SparkContext.scala:704)\n",
      "\tat org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:231)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat scala.util.Try$.apply(Try.scala:217)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:205)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:184)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: java.io.IOException: Cannot run program \"rm\": error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1170)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1089)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:183)\n",
      "\t... 33 more\n",
      "Caused by: java.io.IOException: error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessImpl.forkAndExec(Native Method)\n",
      "\tat java.base/java.lang.ProcessImpl.<init>(ProcessImpl.java:295)\n",
      "\tat java.base/java.lang.ProcessImpl.start(ProcessImpl.java:225)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1126)\n",
      "\t... 35 more\n",
      "25/11/20 12:05:20 WARN JavaUtils: Attempt to delete using native Unix OS command failed for path = /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/34/shuffle_0_0_0.checksum.ADLER32. Falling back to Java IO way\n",
      "java.io.IOException: Failed to delete: /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/34/shuffle_0_0_0.checksum.ADLER32\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:191)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:116)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120)\n",
      "\tat org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1048)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1(DiskBlockManager.scala:372)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1$adapted(DiskBlockManager.scala:368)\n",
      "\tat scala.collection.ArrayOps$.foreach$extension(ArrayOps.scala:1324)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.doStop(DiskBlockManager.scala:368)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.stop(DiskBlockManager.scala:363)\n",
      "\tat org.apache.spark.storage.BlockManager.stop(BlockManager.scala:2166)\n",
      "\tat org.apache.spark.SparkEnv.stop(SparkEnv.scala:118)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1300)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2297)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$36(SparkContext.scala:704)\n",
      "\tat org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:231)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat scala.util.Try$.apply(Try.scala:217)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:205)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:184)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: java.io.IOException: Cannot run program \"rm\": error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1170)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1089)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:183)\n",
      "\t... 35 more\n",
      "Caused by: java.io.IOException: error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessImpl.forkAndExec(Native Method)\n",
      "\tat java.base/java.lang.ProcessImpl.<init>(ProcessImpl.java:295)\n",
      "\tat java.base/java.lang.ProcessImpl.start(ProcessImpl.java:225)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1126)\n",
      "\t... 37 more\n",
      "25/11/20 12:05:20 WARN JavaUtils: Attempt to delete using native Unix OS command failed for path = /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/33. Falling back to Java IO way\n",
      "java.io.IOException: Failed to delete: /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/33\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:191)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:116)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120)\n",
      "\tat org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1048)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1(DiskBlockManager.scala:372)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1$adapted(DiskBlockManager.scala:368)\n",
      "\tat scala.collection.ArrayOps$.foreach$extension(ArrayOps.scala:1324)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.doStop(DiskBlockManager.scala:368)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.stop(DiskBlockManager.scala:363)\n",
      "\tat org.apache.spark.storage.BlockManager.stop(BlockManager.scala:2166)\n",
      "\tat org.apache.spark.SparkEnv.stop(SparkEnv.scala:118)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1300)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2297)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$36(SparkContext.scala:704)\n",
      "\tat org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:231)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat scala.util.Try$.apply(Try.scala:217)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:205)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:184)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: java.io.IOException: Cannot run program \"rm\": error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1170)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1089)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:183)\n",
      "\t... 33 more\n",
      "Caused by: java.io.IOException: error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessImpl.forkAndExec(Native Method)\n",
      "\tat java.base/java.lang.ProcessImpl.<init>(ProcessImpl.java:295)\n",
      "\tat java.base/java.lang.ProcessImpl.start(ProcessImpl.java:225)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1126)\n",
      "\t... 35 more\n",
      "25/11/20 12:05:20 WARN JavaUtils: Attempt to delete using native Unix OS command failed for path = /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/05. Falling back to Java IO way\n",
      "java.io.IOException: Failed to delete: /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/05\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:191)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:116)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120)\n",
      "\tat org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1048)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1(DiskBlockManager.scala:372)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1$adapted(DiskBlockManager.scala:368)\n",
      "\tat scala.collection.ArrayOps$.foreach$extension(ArrayOps.scala:1324)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.doStop(DiskBlockManager.scala:368)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.stop(DiskBlockManager.scala:363)\n",
      "\tat org.apache.spark.storage.BlockManager.stop(BlockManager.scala:2166)\n",
      "\tat org.apache.spark.SparkEnv.stop(SparkEnv.scala:118)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1300)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2297)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$36(SparkContext.scala:704)\n",
      "\tat org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:231)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat scala.util.Try$.apply(Try.scala:217)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:205)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:184)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: java.io.IOException: Cannot run program \"rm\": error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1170)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1089)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:183)\n",
      "\t... 33 more\n",
      "Caused by: java.io.IOException: error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessImpl.forkAndExec(Native Method)\n",
      "\tat java.base/java.lang.ProcessImpl.<init>(ProcessImpl.java:295)\n",
      "\tat java.base/java.lang.ProcessImpl.start(ProcessImpl.java:225)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1126)\n",
      "\t... 35 more\n",
      "25/11/20 12:05:20 WARN JavaUtils: Attempt to delete using native Unix OS command failed for path = /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/20. Falling back to Java IO way\n",
      "java.io.IOException: Failed to delete: /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/20\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:191)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:116)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120)\n",
      "\tat org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1048)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1(DiskBlockManager.scala:372)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1$adapted(DiskBlockManager.scala:368)\n",
      "\tat scala.collection.ArrayOps$.foreach$extension(ArrayOps.scala:1324)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.doStop(DiskBlockManager.scala:368)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.stop(DiskBlockManager.scala:363)\n",
      "\tat org.apache.spark.storage.BlockManager.stop(BlockManager.scala:2166)\n",
      "\tat org.apache.spark.SparkEnv.stop(SparkEnv.scala:118)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1300)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2297)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$36(SparkContext.scala:704)\n",
      "\tat org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:231)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat scala.util.Try$.apply(Try.scala:217)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:205)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:184)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: java.io.IOException: Cannot run program \"rm\": error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1170)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1089)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:183)\n",
      "\t... 33 more\n",
      "Caused by: java.io.IOException: error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessImpl.forkAndExec(Native Method)\n",
      "\tat java.base/java.lang.ProcessImpl.<init>(ProcessImpl.java:295)\n",
      "\tat java.base/java.lang.ProcessImpl.start(ProcessImpl.java:225)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1126)\n",
      "\t... 35 more\n",
      "25/11/20 12:05:20 WARN JavaUtils: Attempt to delete using native Unix OS command failed for path = /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/27. Falling back to Java IO way\n",
      "java.io.IOException: Failed to delete: /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/27\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:191)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:116)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120)\n",
      "\tat org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1048)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1(DiskBlockManager.scala:372)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1$adapted(DiskBlockManager.scala:368)\n",
      "\tat scala.collection.ArrayOps$.foreach$extension(ArrayOps.scala:1324)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.doStop(DiskBlockManager.scala:368)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.stop(DiskBlockManager.scala:363)\n",
      "\tat org.apache.spark.storage.BlockManager.stop(BlockManager.scala:2166)\n",
      "\tat org.apache.spark.SparkEnv.stop(SparkEnv.scala:118)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1300)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2297)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$36(SparkContext.scala:704)\n",
      "\tat org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:231)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat scala.util.Try$.apply(Try.scala:217)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:205)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:184)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: java.io.IOException: Cannot run program \"rm\": error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1170)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1089)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:183)\n",
      "\t... 33 more\n",
      "Caused by: java.io.IOException: error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessImpl.forkAndExec(Native Method)\n",
      "\tat java.base/java.lang.ProcessImpl.<init>(ProcessImpl.java:295)\n",
      "\tat java.base/java.lang.ProcessImpl.start(ProcessImpl.java:225)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1126)\n",
      "\t... 35 more\n",
      "25/11/20 12:05:20 WARN JavaUtils: Attempt to delete using native Unix OS command failed for path = /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/27/shuffle_1_4_0.checksum.ADLER32. Falling back to Java IO way\n",
      "java.io.IOException: Failed to delete: /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/27/shuffle_1_4_0.checksum.ADLER32\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:191)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:116)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120)\n",
      "\tat org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1048)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1(DiskBlockManager.scala:372)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1$adapted(DiskBlockManager.scala:368)\n",
      "\tat scala.collection.ArrayOps$.foreach$extension(ArrayOps.scala:1324)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.doStop(DiskBlockManager.scala:368)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.stop(DiskBlockManager.scala:363)\n",
      "\tat org.apache.spark.storage.BlockManager.stop(BlockManager.scala:2166)\n",
      "\tat org.apache.spark.SparkEnv.stop(SparkEnv.scala:118)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1300)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2297)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$36(SparkContext.scala:704)\n",
      "\tat org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:231)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat scala.util.Try$.apply(Try.scala:217)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:205)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:184)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: java.io.IOException: Cannot run program \"rm\": error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1170)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1089)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:183)\n",
      "\t... 35 more\n",
      "Caused by: java.io.IOException: error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessImpl.forkAndExec(Native Method)\n",
      "\tat java.base/java.lang.ProcessImpl.<init>(ProcessImpl.java:295)\n",
      "\tat java.base/java.lang.ProcessImpl.start(ProcessImpl.java:225)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1126)\n",
      "\t... 37 more\n",
      "25/11/20 12:05:20 WARN JavaUtils: Attempt to delete using native Unix OS command failed for path = /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/11. Falling back to Java IO way\n",
      "java.io.IOException: Failed to delete: /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/11\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:191)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:116)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120)\n",
      "\tat org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1048)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1(DiskBlockManager.scala:372)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1$adapted(DiskBlockManager.scala:368)\n",
      "\tat scala.collection.ArrayOps$.foreach$extension(ArrayOps.scala:1324)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.doStop(DiskBlockManager.scala:368)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.stop(DiskBlockManager.scala:363)\n",
      "\tat org.apache.spark.storage.BlockManager.stop(BlockManager.scala:2166)\n",
      "\tat org.apache.spark.SparkEnv.stop(SparkEnv.scala:118)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1300)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2297)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$36(SparkContext.scala:704)\n",
      "\tat org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:231)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat scala.util.Try$.apply(Try.scala:217)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:205)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:184)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: java.io.IOException: Cannot run program \"rm\": error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1170)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1089)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:183)\n",
      "\t... 33 more\n",
      "Caused by: java.io.IOException: error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessImpl.forkAndExec(Native Method)\n",
      "\tat java.base/java.lang.ProcessImpl.<init>(ProcessImpl.java:295)\n",
      "\tat java.base/java.lang.ProcessImpl.start(ProcessImpl.java:225)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1126)\n",
      "\t... 35 more\n",
      "25/11/20 12:05:20 WARN JavaUtils: Attempt to delete using native Unix OS command failed for path = /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/29. Falling back to Java IO way\n",
      "java.io.IOException: Failed to delete: /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/29\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:191)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:116)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120)\n",
      "\tat org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1048)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1(DiskBlockManager.scala:372)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1$adapted(DiskBlockManager.scala:368)\n",
      "\tat scala.collection.ArrayOps$.foreach$extension(ArrayOps.scala:1324)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.doStop(DiskBlockManager.scala:368)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.stop(DiskBlockManager.scala:363)\n",
      "\tat org.apache.spark.storage.BlockManager.stop(BlockManager.scala:2166)\n",
      "\tat org.apache.spark.SparkEnv.stop(SparkEnv.scala:118)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1300)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2297)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$36(SparkContext.scala:704)\n",
      "\tat org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:231)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat scala.util.Try$.apply(Try.scala:217)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:205)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:184)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: java.io.IOException: Cannot run program \"rm\": error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1170)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1089)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:183)\n",
      "\t... 33 more\n",
      "Caused by: java.io.IOException: error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessImpl.forkAndExec(Native Method)\n",
      "\tat java.base/java.lang.ProcessImpl.<init>(ProcessImpl.java:295)\n",
      "\tat java.base/java.lang.ProcessImpl.start(ProcessImpl.java:225)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1126)\n",
      "\t... 35 more\n",
      "25/11/20 12:05:20 WARN JavaUtils: Attempt to delete using native Unix OS command failed for path = /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/1f. Falling back to Java IO way\n",
      "java.io.IOException: Failed to delete: /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/1f\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:191)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:116)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120)\n",
      "\tat org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1048)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1(DiskBlockManager.scala:372)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1$adapted(DiskBlockManager.scala:368)\n",
      "\tat scala.collection.ArrayOps$.foreach$extension(ArrayOps.scala:1324)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.doStop(DiskBlockManager.scala:368)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.stop(DiskBlockManager.scala:363)\n",
      "\tat org.apache.spark.storage.BlockManager.stop(BlockManager.scala:2166)\n",
      "\tat org.apache.spark.SparkEnv.stop(SparkEnv.scala:118)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1300)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2297)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$36(SparkContext.scala:704)\n",
      "\tat org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:231)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat scala.util.Try$.apply(Try.scala:217)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:205)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:184)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: java.io.IOException: Cannot run program \"rm\": error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1170)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1089)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:183)\n",
      "\t... 33 more\n",
      "Caused by: java.io.IOException: error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessImpl.forkAndExec(Native Method)\n",
      "\tat java.base/java.lang.ProcessImpl.<init>(ProcessImpl.java:295)\n",
      "\tat java.base/java.lang.ProcessImpl.start(ProcessImpl.java:225)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1126)\n",
      "\t... 35 more\n",
      "25/11/20 12:05:20 WARN JavaUtils: Attempt to delete using native Unix OS command failed for path = /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/1a. Falling back to Java IO way\n",
      "java.io.IOException: Failed to delete: /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/1a\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:191)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:116)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120)\n",
      "\tat org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1048)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1(DiskBlockManager.scala:372)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1$adapted(DiskBlockManager.scala:368)\n",
      "\tat scala.collection.ArrayOps$.foreach$extension(ArrayOps.scala:1324)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.doStop(DiskBlockManager.scala:368)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.stop(DiskBlockManager.scala:363)\n",
      "\tat org.apache.spark.storage.BlockManager.stop(BlockManager.scala:2166)\n",
      "\tat org.apache.spark.SparkEnv.stop(SparkEnv.scala:118)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1300)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2297)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$36(SparkContext.scala:704)\n",
      "\tat org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:231)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat scala.util.Try$.apply(Try.scala:217)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:205)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:184)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: java.io.IOException: Cannot run program \"rm\": error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1170)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1089)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:183)\n",
      "\t... 33 more\n",
      "Caused by: java.io.IOException: error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessImpl.forkAndExec(Native Method)\n",
      "\tat java.base/java.lang.ProcessImpl.<init>(ProcessImpl.java:295)\n",
      "\tat java.base/java.lang.ProcessImpl.start(ProcessImpl.java:225)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1126)\n",
      "\t... 35 more\n",
      "25/11/20 12:05:20 WARN JavaUtils: Attempt to delete using native Unix OS command failed for path = /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/19. Falling back to Java IO way\n",
      "java.io.IOException: Failed to delete: /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/19\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:191)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:116)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120)\n",
      "\tat org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1048)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1(DiskBlockManager.scala:372)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1$adapted(DiskBlockManager.scala:368)\n",
      "\tat scala.collection.ArrayOps$.foreach$extension(ArrayOps.scala:1324)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.doStop(DiskBlockManager.scala:368)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.stop(DiskBlockManager.scala:363)\n",
      "\tat org.apache.spark.storage.BlockManager.stop(BlockManager.scala:2166)\n",
      "\tat org.apache.spark.SparkEnv.stop(SparkEnv.scala:118)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1300)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2297)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$36(SparkContext.scala:704)\n",
      "\tat org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:231)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat scala.util.Try$.apply(Try.scala:217)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:205)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:184)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: java.io.IOException: Cannot run program \"rm\": error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1170)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1089)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:183)\n",
      "\t... 33 more\n",
      "Caused by: java.io.IOException: error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessImpl.forkAndExec(Native Method)\n",
      "\tat java.base/java.lang.ProcessImpl.<init>(ProcessImpl.java:295)\n",
      "\tat java.base/java.lang.ProcessImpl.start(ProcessImpl.java:225)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1126)\n",
      "\t... 35 more\n",
      "25/11/20 12:05:20 WARN JavaUtils: Attempt to delete using native Unix OS command failed for path = /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/19/shuffle_1_4_0.data. Falling back to Java IO way\n",
      "java.io.IOException: Failed to delete: /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/19/shuffle_1_4_0.data\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:191)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:116)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120)\n",
      "\tat org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1048)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1(DiskBlockManager.scala:372)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1$adapted(DiskBlockManager.scala:368)\n",
      "\tat scala.collection.ArrayOps$.foreach$extension(ArrayOps.scala:1324)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.doStop(DiskBlockManager.scala:368)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.stop(DiskBlockManager.scala:363)\n",
      "\tat org.apache.spark.storage.BlockManager.stop(BlockManager.scala:2166)\n",
      "\tat org.apache.spark.SparkEnv.stop(SparkEnv.scala:118)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1300)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2297)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$36(SparkContext.scala:704)\n",
      "\tat org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:231)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat scala.util.Try$.apply(Try.scala:217)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:205)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:184)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: java.io.IOException: Cannot run program \"rm\": error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1170)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1089)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:183)\n",
      "\t... 35 more\n",
      "Caused by: java.io.IOException: error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessImpl.forkAndExec(Native Method)\n",
      "\tat java.base/java.lang.ProcessImpl.<init>(ProcessImpl.java:295)\n",
      "\tat java.base/java.lang.ProcessImpl.start(ProcessImpl.java:225)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1126)\n",
      "\t... 37 more\n",
      "25/11/20 12:05:20 WARN JavaUtils: Attempt to delete using native Unix OS command failed for path = /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/21. Falling back to Java IO way\n",
      "java.io.IOException: Failed to delete: /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/21\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:191)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:116)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120)\n",
      "\tat org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1048)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1(DiskBlockManager.scala:372)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1$adapted(DiskBlockManager.scala:368)\n",
      "\tat scala.collection.ArrayOps$.foreach$extension(ArrayOps.scala:1324)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.doStop(DiskBlockManager.scala:368)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.stop(DiskBlockManager.scala:363)\n",
      "\tat org.apache.spark.storage.BlockManager.stop(BlockManager.scala:2166)\n",
      "\tat org.apache.spark.SparkEnv.stop(SparkEnv.scala:118)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1300)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2297)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$36(SparkContext.scala:704)\n",
      "\tat org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:231)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat scala.util.Try$.apply(Try.scala:217)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:205)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:184)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: java.io.IOException: Cannot run program \"rm\": error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1170)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1089)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:183)\n",
      "\t... 33 more\n",
      "Caused by: java.io.IOException: error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessImpl.forkAndExec(Native Method)\n",
      "\tat java.base/java.lang.ProcessImpl.<init>(ProcessImpl.java:295)\n",
      "\tat java.base/java.lang.ProcessImpl.start(ProcessImpl.java:225)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1126)\n",
      "\t... 35 more\n",
      "25/11/20 12:05:20 WARN JavaUtils: Attempt to delete using native Unix OS command failed for path = /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/07. Falling back to Java IO way\n",
      "java.io.IOException: Failed to delete: /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/07\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:191)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:116)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120)\n",
      "\tat org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1048)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1(DiskBlockManager.scala:372)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1$adapted(DiskBlockManager.scala:368)\n",
      "\tat scala.collection.ArrayOps$.foreach$extension(ArrayOps.scala:1324)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.doStop(DiskBlockManager.scala:368)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.stop(DiskBlockManager.scala:363)\n",
      "\tat org.apache.spark.storage.BlockManager.stop(BlockManager.scala:2166)\n",
      "\tat org.apache.spark.SparkEnv.stop(SparkEnv.scala:118)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1300)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2297)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$36(SparkContext.scala:704)\n",
      "\tat org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:231)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat scala.util.Try$.apply(Try.scala:217)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:205)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:184)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: java.io.IOException: Cannot run program \"rm\": error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1170)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1089)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:183)\n",
      "\t... 33 more\n",
      "Caused by: java.io.IOException: error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessImpl.forkAndExec(Native Method)\n",
      "\tat java.base/java.lang.ProcessImpl.<init>(ProcessImpl.java:295)\n",
      "\tat java.base/java.lang.ProcessImpl.start(ProcessImpl.java:225)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1126)\n",
      "\t... 35 more\n",
      "25/11/20 12:05:20 WARN JavaUtils: Attempt to delete using native Unix OS command failed for path = /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/38. Falling back to Java IO way\n",
      "java.io.IOException: Failed to delete: /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/38\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:191)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:116)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120)\n",
      "\tat org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1048)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1(DiskBlockManager.scala:372)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1$adapted(DiskBlockManager.scala:368)\n",
      "\tat scala.collection.ArrayOps$.foreach$extension(ArrayOps.scala:1324)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.doStop(DiskBlockManager.scala:368)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.stop(DiskBlockManager.scala:363)\n",
      "\tat org.apache.spark.storage.BlockManager.stop(BlockManager.scala:2166)\n",
      "\tat org.apache.spark.SparkEnv.stop(SparkEnv.scala:118)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1300)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2297)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$36(SparkContext.scala:704)\n",
      "\tat org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:231)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat scala.util.Try$.apply(Try.scala:217)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:205)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:184)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: java.io.IOException: Cannot run program \"rm\": error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1170)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1089)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:183)\n",
      "\t... 33 more\n",
      "Caused by: java.io.IOException: error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessImpl.forkAndExec(Native Method)\n",
      "\tat java.base/java.lang.ProcessImpl.<init>(ProcessImpl.java:295)\n",
      "\tat java.base/java.lang.ProcessImpl.start(ProcessImpl.java:225)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1126)\n",
      "\t... 35 more\n",
      "25/11/20 12:05:20 WARN JavaUtils: Attempt to delete using native Unix OS command failed for path = /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/36. Falling back to Java IO way\n",
      "java.io.IOException: Failed to delete: /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/36\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:191)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:116)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120)\n",
      "\tat org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1048)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1(DiskBlockManager.scala:372)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1$adapted(DiskBlockManager.scala:368)\n",
      "\tat scala.collection.ArrayOps$.foreach$extension(ArrayOps.scala:1324)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.doStop(DiskBlockManager.scala:368)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.stop(DiskBlockManager.scala:363)\n",
      "\tat org.apache.spark.storage.BlockManager.stop(BlockManager.scala:2166)\n",
      "\tat org.apache.spark.SparkEnv.stop(SparkEnv.scala:118)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1300)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2297)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$36(SparkContext.scala:704)\n",
      "\tat org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:231)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat scala.util.Try$.apply(Try.scala:217)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:205)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:184)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: java.io.IOException: Cannot run program \"rm\": error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1170)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1089)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:183)\n",
      "\t... 33 more\n",
      "Caused by: java.io.IOException: error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessImpl.forkAndExec(Native Method)\n",
      "\tat java.base/java.lang.ProcessImpl.<init>(ProcessImpl.java:295)\n",
      "\tat java.base/java.lang.ProcessImpl.start(ProcessImpl.java:225)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1126)\n",
      "\t... 35 more\n",
      "25/11/20 12:05:20 WARN JavaUtils: Attempt to delete using native Unix OS command failed for path = /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/09. Falling back to Java IO way\n",
      "java.io.IOException: Failed to delete: /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/09\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:191)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:116)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120)\n",
      "\tat org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1048)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1(DiskBlockManager.scala:372)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1$adapted(DiskBlockManager.scala:368)\n",
      "\tat scala.collection.ArrayOps$.foreach$extension(ArrayOps.scala:1324)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.doStop(DiskBlockManager.scala:368)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.stop(DiskBlockManager.scala:363)\n",
      "\tat org.apache.spark.storage.BlockManager.stop(BlockManager.scala:2166)\n",
      "\tat org.apache.spark.SparkEnv.stop(SparkEnv.scala:118)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1300)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2297)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$36(SparkContext.scala:704)\n",
      "\tat org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:231)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat scala.util.Try$.apply(Try.scala:217)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:205)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:184)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: java.io.IOException: Cannot run program \"rm\": error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1170)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1089)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:183)\n",
      "\t... 33 more\n",
      "Caused by: java.io.IOException: error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessImpl.forkAndExec(Native Method)\n",
      "\tat java.base/java.lang.ProcessImpl.<init>(ProcessImpl.java:295)\n",
      "\tat java.base/java.lang.ProcessImpl.start(ProcessImpl.java:225)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1126)\n",
      "\t... 35 more\n",
      "25/11/20 12:05:20 WARN JavaUtils: Attempt to delete using native Unix OS command failed for path = /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/3a. Falling back to Java IO way\n",
      "java.io.IOException: Failed to delete: /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/3a\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:191)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:116)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120)\n",
      "\tat org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1048)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1(DiskBlockManager.scala:372)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1$adapted(DiskBlockManager.scala:368)\n",
      "\tat scala.collection.ArrayOps$.foreach$extension(ArrayOps.scala:1324)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.doStop(DiskBlockManager.scala:368)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.stop(DiskBlockManager.scala:363)\n",
      "\tat org.apache.spark.storage.BlockManager.stop(BlockManager.scala:2166)\n",
      "\tat org.apache.spark.SparkEnv.stop(SparkEnv.scala:118)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1300)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2297)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$36(SparkContext.scala:704)\n",
      "\tat org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:231)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat scala.util.Try$.apply(Try.scala:217)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:205)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:184)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: java.io.IOException: Cannot run program \"rm\": error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1170)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1089)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:183)\n",
      "\t... 33 more\n",
      "Caused by: java.io.IOException: error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessImpl.forkAndExec(Native Method)\n",
      "\tat java.base/java.lang.ProcessImpl.<init>(ProcessImpl.java:295)\n",
      "\tat java.base/java.lang.ProcessImpl.start(ProcessImpl.java:225)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1126)\n",
      "\t... 35 more\n",
      "25/11/20 12:05:20 WARN JavaUtils: Attempt to delete using native Unix OS command failed for path = /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/3f. Falling back to Java IO way\n",
      "java.io.IOException: Failed to delete: /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/3f\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:191)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:116)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120)\n",
      "\tat org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1048)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1(DiskBlockManager.scala:372)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1$adapted(DiskBlockManager.scala:368)\n",
      "\tat scala.collection.ArrayOps$.foreach$extension(ArrayOps.scala:1324)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.doStop(DiskBlockManager.scala:368)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.stop(DiskBlockManager.scala:363)\n",
      "\tat org.apache.spark.storage.BlockManager.stop(BlockManager.scala:2166)\n",
      "\tat org.apache.spark.SparkEnv.stop(SparkEnv.scala:118)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1300)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2297)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$36(SparkContext.scala:704)\n",
      "\tat org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:231)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat scala.util.Try$.apply(Try.scala:217)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:205)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:184)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: java.io.IOException: Cannot run program \"rm\": error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1170)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1089)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:183)\n",
      "\t... 33 more\n",
      "Caused by: java.io.IOException: error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessImpl.forkAndExec(Native Method)\n",
      "\tat java.base/java.lang.ProcessImpl.<init>(ProcessImpl.java:295)\n",
      "\tat java.base/java.lang.ProcessImpl.start(ProcessImpl.java:225)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1126)\n",
      "\t... 35 more\n",
      "25/11/20 12:05:20 WARN JavaUtils: Attempt to delete using native Unix OS command failed for path = /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/30. Falling back to Java IO way\n",
      "java.io.IOException: Failed to delete: /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/30\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:191)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:116)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120)\n",
      "\tat org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1048)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1(DiskBlockManager.scala:372)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1$adapted(DiskBlockManager.scala:368)\n",
      "\tat scala.collection.ArrayOps$.foreach$extension(ArrayOps.scala:1324)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.doStop(DiskBlockManager.scala:368)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.stop(DiskBlockManager.scala:363)\n",
      "\tat org.apache.spark.storage.BlockManager.stop(BlockManager.scala:2166)\n",
      "\tat org.apache.spark.SparkEnv.stop(SparkEnv.scala:118)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1300)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2297)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$36(SparkContext.scala:704)\n",
      "\tat org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:231)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat scala.util.Try$.apply(Try.scala:217)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:205)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:184)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: java.io.IOException: Cannot run program \"rm\": error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1170)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1089)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:183)\n",
      "\t... 33 more\n",
      "Caused by: java.io.IOException: error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessImpl.forkAndExec(Native Method)\n",
      "\tat java.base/java.lang.ProcessImpl.<init>(ProcessImpl.java:295)\n",
      "\tat java.base/java.lang.ProcessImpl.start(ProcessImpl.java:225)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1126)\n",
      "\t... 35 more\n",
      "25/11/20 12:05:20 WARN JavaUtils: Attempt to delete using native Unix OS command failed for path = /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/30/shuffle_0_0_0.index. Falling back to Java IO way\n",
      "java.io.IOException: Failed to delete: /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/30/shuffle_0_0_0.index\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:191)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:116)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120)\n",
      "\tat org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1048)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1(DiskBlockManager.scala:372)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1$adapted(DiskBlockManager.scala:368)\n",
      "\tat scala.collection.ArrayOps$.foreach$extension(ArrayOps.scala:1324)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.doStop(DiskBlockManager.scala:368)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.stop(DiskBlockManager.scala:363)\n",
      "\tat org.apache.spark.storage.BlockManager.stop(BlockManager.scala:2166)\n",
      "\tat org.apache.spark.SparkEnv.stop(SparkEnv.scala:118)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1300)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2297)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$36(SparkContext.scala:704)\n",
      "\tat org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:231)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat scala.util.Try$.apply(Try.scala:217)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:205)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:184)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: java.io.IOException: Cannot run program \"rm\": error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1170)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1089)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:183)\n",
      "\t... 35 more\n",
      "Caused by: java.io.IOException: error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessImpl.forkAndExec(Native Method)\n",
      "\tat java.base/java.lang.ProcessImpl.<init>(ProcessImpl.java:295)\n",
      "\tat java.base/java.lang.ProcessImpl.start(ProcessImpl.java:225)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1126)\n",
      "\t... 37 more\n",
      "25/11/20 12:05:20 WARN JavaUtils: Attempt to delete using native Unix OS command failed for path = /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/37. Falling back to Java IO way\n",
      "java.io.IOException: Failed to delete: /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/37\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:191)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:116)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120)\n",
      "\tat org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1048)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1(DiskBlockManager.scala:372)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1$adapted(DiskBlockManager.scala:368)\n",
      "\tat scala.collection.ArrayOps$.foreach$extension(ArrayOps.scala:1324)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.doStop(DiskBlockManager.scala:368)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.stop(DiskBlockManager.scala:363)\n",
      "\tat org.apache.spark.storage.BlockManager.stop(BlockManager.scala:2166)\n",
      "\tat org.apache.spark.SparkEnv.stop(SparkEnv.scala:118)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1300)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2297)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$36(SparkContext.scala:704)\n",
      "\tat org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:231)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat scala.util.Try$.apply(Try.scala:217)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:205)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:184)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: java.io.IOException: Cannot run program \"rm\": error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1170)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1089)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:183)\n",
      "\t... 33 more\n",
      "Caused by: java.io.IOException: error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessImpl.forkAndExec(Native Method)\n",
      "\tat java.base/java.lang.ProcessImpl.<init>(ProcessImpl.java:295)\n",
      "\tat java.base/java.lang.ProcessImpl.start(ProcessImpl.java:225)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1126)\n",
      "\t... 35 more\n",
      "25/11/20 12:05:20 WARN JavaUtils: Attempt to delete using native Unix OS command failed for path = /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/08. Falling back to Java IO way\n",
      "java.io.IOException: Failed to delete: /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/08\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:191)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:116)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120)\n",
      "\tat org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1048)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1(DiskBlockManager.scala:372)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1$adapted(DiskBlockManager.scala:368)\n",
      "\tat scala.collection.ArrayOps$.foreach$extension(ArrayOps.scala:1324)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.doStop(DiskBlockManager.scala:368)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.stop(DiskBlockManager.scala:363)\n",
      "\tat org.apache.spark.storage.BlockManager.stop(BlockManager.scala:2166)\n",
      "\tat org.apache.spark.SparkEnv.stop(SparkEnv.scala:118)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1300)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2297)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$36(SparkContext.scala:704)\n",
      "\tat org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:231)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat scala.util.Try$.apply(Try.scala:217)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:205)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:184)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: java.io.IOException: Cannot run program \"rm\": error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1170)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1089)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:183)\n",
      "\t... 33 more\n",
      "Caused by: java.io.IOException: error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessImpl.forkAndExec(Native Method)\n",
      "\tat java.base/java.lang.ProcessImpl.<init>(ProcessImpl.java:295)\n",
      "\tat java.base/java.lang.ProcessImpl.start(ProcessImpl.java:225)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1126)\n",
      "\t... 35 more\n",
      "25/11/20 12:05:20 WARN JavaUtils: Attempt to delete using native Unix OS command failed for path = /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/01. Falling back to Java IO way\n",
      "java.io.IOException: Failed to delete: /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/01\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:191)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:116)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120)\n",
      "\tat org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1048)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1(DiskBlockManager.scala:372)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1$adapted(DiskBlockManager.scala:368)\n",
      "\tat scala.collection.ArrayOps$.foreach$extension(ArrayOps.scala:1324)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.doStop(DiskBlockManager.scala:368)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.stop(DiskBlockManager.scala:363)\n",
      "\tat org.apache.spark.storage.BlockManager.stop(BlockManager.scala:2166)\n",
      "\tat org.apache.spark.SparkEnv.stop(SparkEnv.scala:118)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1300)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2297)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$36(SparkContext.scala:704)\n",
      "\tat org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:231)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat scala.util.Try$.apply(Try.scala:217)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:205)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:184)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: java.io.IOException: Cannot run program \"rm\": error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1170)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1089)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:183)\n",
      "\t... 33 more\n",
      "Caused by: java.io.IOException: error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessImpl.forkAndExec(Native Method)\n",
      "\tat java.base/java.lang.ProcessImpl.<init>(ProcessImpl.java:295)\n",
      "\tat java.base/java.lang.ProcessImpl.start(ProcessImpl.java:225)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1126)\n",
      "\t... 35 more\n",
      "25/11/20 12:05:20 WARN JavaUtils: Attempt to delete using native Unix OS command failed for path = /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/06. Falling back to Java IO way\n",
      "java.io.IOException: Failed to delete: /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/06\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:191)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:116)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120)\n",
      "\tat org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1048)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1(DiskBlockManager.scala:372)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1$adapted(DiskBlockManager.scala:368)\n",
      "\tat scala.collection.ArrayOps$.foreach$extension(ArrayOps.scala:1324)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.doStop(DiskBlockManager.scala:368)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.stop(DiskBlockManager.scala:363)\n",
      "\tat org.apache.spark.storage.BlockManager.stop(BlockManager.scala:2166)\n",
      "\tat org.apache.spark.SparkEnv.stop(SparkEnv.scala:118)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1300)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2297)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$36(SparkContext.scala:704)\n",
      "\tat org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:231)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat scala.util.Try$.apply(Try.scala:217)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:205)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:184)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: java.io.IOException: Cannot run program \"rm\": error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1170)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1089)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:183)\n",
      "\t... 33 more\n",
      "Caused by: java.io.IOException: error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessImpl.forkAndExec(Native Method)\n",
      "\tat java.base/java.lang.ProcessImpl.<init>(ProcessImpl.java:295)\n",
      "\tat java.base/java.lang.ProcessImpl.start(ProcessImpl.java:225)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1126)\n",
      "\t... 35 more\n",
      "25/11/20 12:05:20 WARN JavaUtils: Attempt to delete using native Unix OS command failed for path = /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/06/shuffle_1_5_0.data. Falling back to Java IO way\n",
      "java.io.IOException: Failed to delete: /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/06/shuffle_1_5_0.data\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:191)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:116)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120)\n",
      "\tat org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1048)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1(DiskBlockManager.scala:372)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1$adapted(DiskBlockManager.scala:368)\n",
      "\tat scala.collection.ArrayOps$.foreach$extension(ArrayOps.scala:1324)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.doStop(DiskBlockManager.scala:368)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.stop(DiskBlockManager.scala:363)\n",
      "\tat org.apache.spark.storage.BlockManager.stop(BlockManager.scala:2166)\n",
      "\tat org.apache.spark.SparkEnv.stop(SparkEnv.scala:118)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1300)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2297)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$36(SparkContext.scala:704)\n",
      "\tat org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:231)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat scala.util.Try$.apply(Try.scala:217)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:205)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:184)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: java.io.IOException: Cannot run program \"rm\": error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1170)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1089)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:183)\n",
      "\t... 35 more\n",
      "Caused by: java.io.IOException: error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessImpl.forkAndExec(Native Method)\n",
      "\tat java.base/java.lang.ProcessImpl.<init>(ProcessImpl.java:295)\n",
      "\tat java.base/java.lang.ProcessImpl.start(ProcessImpl.java:225)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1126)\n",
      "\t... 37 more\n",
      "25/11/20 12:05:20 WARN JavaUtils: Attempt to delete using native Unix OS command failed for path = /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/06/shuffle_1_5_0.checksum.ADLER32. Falling back to Java IO way\n",
      "java.io.IOException: Failed to delete: /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/06/shuffle_1_5_0.checksum.ADLER32\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:191)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:116)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120)\n",
      "\tat org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1048)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1(DiskBlockManager.scala:372)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1$adapted(DiskBlockManager.scala:368)\n",
      "\tat scala.collection.ArrayOps$.foreach$extension(ArrayOps.scala:1324)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.doStop(DiskBlockManager.scala:368)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.stop(DiskBlockManager.scala:363)\n",
      "\tat org.apache.spark.storage.BlockManager.stop(BlockManager.scala:2166)\n",
      "\tat org.apache.spark.SparkEnv.stop(SparkEnv.scala:118)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1300)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2297)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$36(SparkContext.scala:704)\n",
      "\tat org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:231)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat scala.util.Try$.apply(Try.scala:217)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:205)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:184)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: java.io.IOException: Cannot run program \"rm\": error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1170)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1089)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:183)\n",
      "\t... 35 more\n",
      "Caused by: java.io.IOException: error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessImpl.forkAndExec(Native Method)\n",
      "\tat java.base/java.lang.ProcessImpl.<init>(ProcessImpl.java:295)\n",
      "\tat java.base/java.lang.ProcessImpl.start(ProcessImpl.java:225)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1126)\n",
      "\t... 37 more\n",
      "25/11/20 12:05:20 WARN JavaUtils: Attempt to delete using native Unix OS command failed for path = /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/0f. Falling back to Java IO way\n",
      "java.io.IOException: Failed to delete: /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/0f\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:191)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:116)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120)\n",
      "\tat org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1048)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1(DiskBlockManager.scala:372)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1$adapted(DiskBlockManager.scala:368)\n",
      "\tat scala.collection.ArrayOps$.foreach$extension(ArrayOps.scala:1324)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.doStop(DiskBlockManager.scala:368)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.stop(DiskBlockManager.scala:363)\n",
      "\tat org.apache.spark.storage.BlockManager.stop(BlockManager.scala:2166)\n",
      "\tat org.apache.spark.SparkEnv.stop(SparkEnv.scala:118)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1300)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2297)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$36(SparkContext.scala:704)\n",
      "\tat org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:231)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat scala.util.Try$.apply(Try.scala:217)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:205)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:184)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: java.io.IOException: Cannot run program \"rm\": error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1170)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1089)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:183)\n",
      "\t... 33 more\n",
      "Caused by: java.io.IOException: error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessImpl.forkAndExec(Native Method)\n",
      "\tat java.base/java.lang.ProcessImpl.<init>(ProcessImpl.java:295)\n",
      "\tat java.base/java.lang.ProcessImpl.start(ProcessImpl.java:225)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1126)\n",
      "\t... 35 more\n",
      "25/11/20 12:05:20 WARN JavaUtils: Attempt to delete using native Unix OS command failed for path = /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/0f/shuffle_0_1_0.index. Falling back to Java IO way\n",
      "java.io.IOException: Failed to delete: /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/0f/shuffle_0_1_0.index\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:191)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:116)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120)\n",
      "\tat org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1048)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1(DiskBlockManager.scala:372)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1$adapted(DiskBlockManager.scala:368)\n",
      "\tat scala.collection.ArrayOps$.foreach$extension(ArrayOps.scala:1324)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.doStop(DiskBlockManager.scala:368)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.stop(DiskBlockManager.scala:363)\n",
      "\tat org.apache.spark.storage.BlockManager.stop(BlockManager.scala:2166)\n",
      "\tat org.apache.spark.SparkEnv.stop(SparkEnv.scala:118)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1300)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2297)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$36(SparkContext.scala:704)\n",
      "\tat org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:231)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat scala.util.Try$.apply(Try.scala:217)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:205)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:184)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: java.io.IOException: Cannot run program \"rm\": error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1170)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1089)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:183)\n",
      "\t... 35 more\n",
      "Caused by: java.io.IOException: error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessImpl.forkAndExec(Native Method)\n",
      "\tat java.base/java.lang.ProcessImpl.<init>(ProcessImpl.java:295)\n",
      "\tat java.base/java.lang.ProcessImpl.start(ProcessImpl.java:225)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1126)\n",
      "\t... 37 more\n",
      "25/11/20 12:05:20 WARN JavaUtils: Attempt to delete using native Unix OS command failed for path = /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/0a. Falling back to Java IO way\n",
      "java.io.IOException: Failed to delete: /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/0a\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:191)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:116)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120)\n",
      "\tat org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1048)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1(DiskBlockManager.scala:372)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1$adapted(DiskBlockManager.scala:368)\n",
      "\tat scala.collection.ArrayOps$.foreach$extension(ArrayOps.scala:1324)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.doStop(DiskBlockManager.scala:368)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.stop(DiskBlockManager.scala:363)\n",
      "\tat org.apache.spark.storage.BlockManager.stop(BlockManager.scala:2166)\n",
      "\tat org.apache.spark.SparkEnv.stop(SparkEnv.scala:118)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1300)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2297)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$36(SparkContext.scala:704)\n",
      "\tat org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:231)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat scala.util.Try$.apply(Try.scala:217)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:205)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:184)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: java.io.IOException: Cannot run program \"rm\": error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1170)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1089)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:183)\n",
      "\t... 33 more\n",
      "Caused by: java.io.IOException: error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessImpl.forkAndExec(Native Method)\n",
      "\tat java.base/java.lang.ProcessImpl.<init>(ProcessImpl.java:295)\n",
      "\tat java.base/java.lang.ProcessImpl.start(ProcessImpl.java:225)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1126)\n",
      "\t... 35 more\n",
      "25/11/20 12:05:20 WARN JavaUtils: Attempt to delete using native Unix OS command failed for path = /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/0a/shuffle_1_5_0.index. Falling back to Java IO way\n",
      "java.io.IOException: Failed to delete: /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/0a/shuffle_1_5_0.index\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:191)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:116)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120)\n",
      "\tat org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1048)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1(DiskBlockManager.scala:372)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1$adapted(DiskBlockManager.scala:368)\n",
      "\tat scala.collection.ArrayOps$.foreach$extension(ArrayOps.scala:1324)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.doStop(DiskBlockManager.scala:368)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.stop(DiskBlockManager.scala:363)\n",
      "\tat org.apache.spark.storage.BlockManager.stop(BlockManager.scala:2166)\n",
      "\tat org.apache.spark.SparkEnv.stop(SparkEnv.scala:118)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1300)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2297)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$36(SparkContext.scala:704)\n",
      "\tat org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:231)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat scala.util.Try$.apply(Try.scala:217)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:205)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:184)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: java.io.IOException: Cannot run program \"rm\": error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1170)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1089)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:183)\n",
      "\t... 35 more\n",
      "Caused by: java.io.IOException: error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessImpl.forkAndExec(Native Method)\n",
      "\tat java.base/java.lang.ProcessImpl.<init>(ProcessImpl.java:295)\n",
      "\tat java.base/java.lang.ProcessImpl.start(ProcessImpl.java:225)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1126)\n",
      "\t... 37 more\n",
      "25/11/20 12:05:20 WARN JavaUtils: Attempt to delete using native Unix OS command failed for path = /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/2c. Falling back to Java IO way\n",
      "java.io.IOException: Failed to delete: /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/2c\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:191)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:116)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120)\n",
      "\tat org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1048)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1(DiskBlockManager.scala:372)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1$adapted(DiskBlockManager.scala:368)\n",
      "\tat scala.collection.ArrayOps$.foreach$extension(ArrayOps.scala:1324)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.doStop(DiskBlockManager.scala:368)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.stop(DiskBlockManager.scala:363)\n",
      "\tat org.apache.spark.storage.BlockManager.stop(BlockManager.scala:2166)\n",
      "\tat org.apache.spark.SparkEnv.stop(SparkEnv.scala:118)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1300)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2297)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$36(SparkContext.scala:704)\n",
      "\tat org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:231)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat scala.util.Try$.apply(Try.scala:217)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:205)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:184)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: java.io.IOException: Cannot run program \"rm\": error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1170)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1089)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:183)\n",
      "\t... 33 more\n",
      "Caused by: java.io.IOException: error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessImpl.forkAndExec(Native Method)\n",
      "\tat java.base/java.lang.ProcessImpl.<init>(ProcessImpl.java:295)\n",
      "\tat java.base/java.lang.ProcessImpl.start(ProcessImpl.java:225)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1126)\n",
      "\t... 35 more\n",
      "25/11/20 12:05:20 WARN JavaUtils: Attempt to delete using native Unix OS command failed for path = /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/1e. Falling back to Java IO way\n",
      "java.io.IOException: Failed to delete: /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/1e\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:191)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:116)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120)\n",
      "\tat org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1048)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1(DiskBlockManager.scala:372)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1$adapted(DiskBlockManager.scala:368)\n",
      "\tat scala.collection.ArrayOps$.foreach$extension(ArrayOps.scala:1324)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.doStop(DiskBlockManager.scala:368)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.stop(DiskBlockManager.scala:363)\n",
      "\tat org.apache.spark.storage.BlockManager.stop(BlockManager.scala:2166)\n",
      "\tat org.apache.spark.SparkEnv.stop(SparkEnv.scala:118)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1300)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2297)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$36(SparkContext.scala:704)\n",
      "\tat org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:231)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat scala.util.Try$.apply(Try.scala:217)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:205)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:184)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: java.io.IOException: Cannot run program \"rm\": error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1170)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1089)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:183)\n",
      "\t... 33 more\n",
      "Caused by: java.io.IOException: error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessImpl.forkAndExec(Native Method)\n",
      "\tat java.base/java.lang.ProcessImpl.<init>(ProcessImpl.java:295)\n",
      "\tat java.base/java.lang.ProcessImpl.start(ProcessImpl.java:225)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1126)\n",
      "\t... 35 more\n",
      "25/11/20 12:05:20 WARN JavaUtils: Attempt to delete using native Unix OS command failed for path = /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/24. Falling back to Java IO way\n",
      "java.io.IOException: Failed to delete: /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/24\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:191)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:116)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120)\n",
      "\tat org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1048)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1(DiskBlockManager.scala:372)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1$adapted(DiskBlockManager.scala:368)\n",
      "\tat scala.collection.ArrayOps$.foreach$extension(ArrayOps.scala:1324)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.doStop(DiskBlockManager.scala:368)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.stop(DiskBlockManager.scala:363)\n",
      "\tat org.apache.spark.storage.BlockManager.stop(BlockManager.scala:2166)\n",
      "\tat org.apache.spark.SparkEnv.stop(SparkEnv.scala:118)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1300)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2297)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$36(SparkContext.scala:704)\n",
      "\tat org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:231)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat scala.util.Try$.apply(Try.scala:217)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:205)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:184)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: java.io.IOException: Cannot run program \"rm\": error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1170)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1089)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:183)\n",
      "\t... 33 more\n",
      "Caused by: java.io.IOException: error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessImpl.forkAndExec(Native Method)\n",
      "\tat java.base/java.lang.ProcessImpl.<init>(ProcessImpl.java:295)\n",
      "\tat java.base/java.lang.ProcessImpl.start(ProcessImpl.java:225)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1126)\n",
      "\t... 35 more\n",
      "25/11/20 12:05:20 WARN JavaUtils: Attempt to delete using native Unix OS command failed for path = /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/23. Falling back to Java IO way\n",
      "java.io.IOException: Failed to delete: /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/23\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:191)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:116)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120)\n",
      "\tat org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1048)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1(DiskBlockManager.scala:372)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1$adapted(DiskBlockManager.scala:368)\n",
      "\tat scala.collection.ArrayOps$.foreach$extension(ArrayOps.scala:1324)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.doStop(DiskBlockManager.scala:368)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.stop(DiskBlockManager.scala:363)\n",
      "\tat org.apache.spark.storage.BlockManager.stop(BlockManager.scala:2166)\n",
      "\tat org.apache.spark.SparkEnv.stop(SparkEnv.scala:118)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1300)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2297)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$36(SparkContext.scala:704)\n",
      "\tat org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:231)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat scala.util.Try$.apply(Try.scala:217)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:205)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:184)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: java.io.IOException: Cannot run program \"rm\": error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1170)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1089)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:183)\n",
      "\t... 33 more\n",
      "Caused by: java.io.IOException: error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessImpl.forkAndExec(Native Method)\n",
      "\tat java.base/java.lang.ProcessImpl.<init>(ProcessImpl.java:295)\n",
      "\tat java.base/java.lang.ProcessImpl.start(ProcessImpl.java:225)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1126)\n",
      "\t... 35 more\n",
      "25/11/20 12:05:20 WARN JavaUtils: Attempt to delete using native Unix OS command failed for path = /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/15. Falling back to Java IO way\n",
      "java.io.IOException: Failed to delete: /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/15\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:191)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:116)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120)\n",
      "\tat org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1048)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1(DiskBlockManager.scala:372)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1$adapted(DiskBlockManager.scala:368)\n",
      "\tat scala.collection.ArrayOps$.foreach$extension(ArrayOps.scala:1324)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.doStop(DiskBlockManager.scala:368)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.stop(DiskBlockManager.scala:363)\n",
      "\tat org.apache.spark.storage.BlockManager.stop(BlockManager.scala:2166)\n",
      "\tat org.apache.spark.SparkEnv.stop(SparkEnv.scala:118)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1300)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2297)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$36(SparkContext.scala:704)\n",
      "\tat org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:231)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat scala.util.Try$.apply(Try.scala:217)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:205)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:184)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: java.io.IOException: Cannot run program \"rm\": error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1170)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1089)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:183)\n",
      "\t... 33 more\n",
      "Caused by: java.io.IOException: error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessImpl.forkAndExec(Native Method)\n",
      "\tat java.base/java.lang.ProcessImpl.<init>(ProcessImpl.java:295)\n",
      "\tat java.base/java.lang.ProcessImpl.start(ProcessImpl.java:225)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1126)\n",
      "\t... 35 more\n",
      "25/11/20 12:05:20 WARN JavaUtils: Attempt to delete using native Unix OS command failed for path = /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/15/shuffle_0_1_0.checksum.ADLER32. Falling back to Java IO way\n",
      "java.io.IOException: Failed to delete: /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/15/shuffle_0_1_0.checksum.ADLER32\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:191)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:116)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120)\n",
      "\tat org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1048)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1(DiskBlockManager.scala:372)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1$adapted(DiskBlockManager.scala:368)\n",
      "\tat scala.collection.ArrayOps$.foreach$extension(ArrayOps.scala:1324)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.doStop(DiskBlockManager.scala:368)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.stop(DiskBlockManager.scala:363)\n",
      "\tat org.apache.spark.storage.BlockManager.stop(BlockManager.scala:2166)\n",
      "\tat org.apache.spark.SparkEnv.stop(SparkEnv.scala:118)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1300)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2297)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$36(SparkContext.scala:704)\n",
      "\tat org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:231)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat scala.util.Try$.apply(Try.scala:217)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:205)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:184)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: java.io.IOException: Cannot run program \"rm\": error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1170)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1089)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:183)\n",
      "\t... 35 more\n",
      "Caused by: java.io.IOException: error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessImpl.forkAndExec(Native Method)\n",
      "\tat java.base/java.lang.ProcessImpl.<init>(ProcessImpl.java:295)\n",
      "\tat java.base/java.lang.ProcessImpl.start(ProcessImpl.java:225)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1126)\n",
      "\t... 37 more\n",
      "25/11/20 12:05:20 WARN JavaUtils: Attempt to delete using native Unix OS command failed for path = /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/15/shuffle_0_1_0.data. Falling back to Java IO way\n",
      "java.io.IOException: Failed to delete: /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/15/shuffle_0_1_0.data\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:191)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:116)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120)\n",
      "\tat org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1048)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1(DiskBlockManager.scala:372)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1$adapted(DiskBlockManager.scala:368)\n",
      "\tat scala.collection.ArrayOps$.foreach$extension(ArrayOps.scala:1324)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.doStop(DiskBlockManager.scala:368)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.stop(DiskBlockManager.scala:363)\n",
      "\tat org.apache.spark.storage.BlockManager.stop(BlockManager.scala:2166)\n",
      "\tat org.apache.spark.SparkEnv.stop(SparkEnv.scala:118)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1300)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2297)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$36(SparkContext.scala:704)\n",
      "\tat org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:231)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat scala.util.Try$.apply(Try.scala:217)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:205)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:184)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: java.io.IOException: Cannot run program \"rm\": error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1170)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1089)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:183)\n",
      "\t... 35 more\n",
      "Caused by: java.io.IOException: error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessImpl.forkAndExec(Native Method)\n",
      "\tat java.base/java.lang.ProcessImpl.<init>(ProcessImpl.java:295)\n",
      "\tat java.base/java.lang.ProcessImpl.start(ProcessImpl.java:225)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1126)\n",
      "\t... 37 more\n",
      "25/11/20 12:05:20 WARN JavaUtils: Attempt to delete using native Unix OS command failed for path = /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/1d. Falling back to Java IO way\n",
      "java.io.IOException: Failed to delete: /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/1d\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:191)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:116)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120)\n",
      "\tat org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1048)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1(DiskBlockManager.scala:372)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1$adapted(DiskBlockManager.scala:368)\n",
      "\tat scala.collection.ArrayOps$.foreach$extension(ArrayOps.scala:1324)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.doStop(DiskBlockManager.scala:368)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.stop(DiskBlockManager.scala:363)\n",
      "\tat org.apache.spark.storage.BlockManager.stop(BlockManager.scala:2166)\n",
      "\tat org.apache.spark.SparkEnv.stop(SparkEnv.scala:118)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1300)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2297)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$36(SparkContext.scala:704)\n",
      "\tat org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:231)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat scala.util.Try$.apply(Try.scala:217)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:205)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:184)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: java.io.IOException: Cannot run program \"rm\": error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1170)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1089)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:183)\n",
      "\t... 33 more\n",
      "Caused by: java.io.IOException: error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessImpl.forkAndExec(Native Method)\n",
      "\tat java.base/java.lang.ProcessImpl.<init>(ProcessImpl.java:295)\n",
      "\tat java.base/java.lang.ProcessImpl.start(ProcessImpl.java:225)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1126)\n",
      "\t... 35 more\n",
      "25/11/20 12:05:20 WARN JavaUtils: Attempt to delete using native Unix OS command failed for path = /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/13. Falling back to Java IO way\n",
      "java.io.IOException: Failed to delete: /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/13\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:191)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:116)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120)\n",
      "\tat org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1048)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1(DiskBlockManager.scala:372)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1$adapted(DiskBlockManager.scala:368)\n",
      "\tat scala.collection.ArrayOps$.foreach$extension(ArrayOps.scala:1324)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.doStop(DiskBlockManager.scala:368)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.stop(DiskBlockManager.scala:363)\n",
      "\tat org.apache.spark.storage.BlockManager.stop(BlockManager.scala:2166)\n",
      "\tat org.apache.spark.SparkEnv.stop(SparkEnv.scala:118)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1300)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2297)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$36(SparkContext.scala:704)\n",
      "\tat org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:231)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat scala.util.Try$.apply(Try.scala:217)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:205)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:184)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: java.io.IOException: Cannot run program \"rm\": error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1170)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1089)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:183)\n",
      "\t... 33 more\n",
      "Caused by: java.io.IOException: error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessImpl.forkAndExec(Native Method)\n",
      "\tat java.base/java.lang.ProcessImpl.<init>(ProcessImpl.java:295)\n",
      "\tat java.base/java.lang.ProcessImpl.start(ProcessImpl.java:225)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1126)\n",
      "\t... 35 more\n",
      "25/11/20 12:05:20 WARN JavaUtils: Attempt to delete using native Unix OS command failed for path = /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/22. Falling back to Java IO way\n",
      "java.io.IOException: Failed to delete: /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/22\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:191)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:116)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120)\n",
      "\tat org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1048)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1(DiskBlockManager.scala:372)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1$adapted(DiskBlockManager.scala:368)\n",
      "\tat scala.collection.ArrayOps$.foreach$extension(ArrayOps.scala:1324)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.doStop(DiskBlockManager.scala:368)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.stop(DiskBlockManager.scala:363)\n",
      "\tat org.apache.spark.storage.BlockManager.stop(BlockManager.scala:2166)\n",
      "\tat org.apache.spark.SparkEnv.stop(SparkEnv.scala:118)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1300)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2297)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$36(SparkContext.scala:704)\n",
      "\tat org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:231)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat scala.util.Try$.apply(Try.scala:217)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:205)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:184)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: java.io.IOException: Cannot run program \"rm\": error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1170)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1089)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:183)\n",
      "\t... 33 more\n",
      "Caused by: java.io.IOException: error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessImpl.forkAndExec(Native Method)\n",
      "\tat java.base/java.lang.ProcessImpl.<init>(ProcessImpl.java:295)\n",
      "\tat java.base/java.lang.ProcessImpl.start(ProcessImpl.java:225)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1126)\n",
      "\t... 35 more\n",
      "25/11/20 12:05:20 WARN JavaUtils: Attempt to delete using native Unix OS command failed for path = /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/25. Falling back to Java IO way\n",
      "java.io.IOException: Failed to delete: /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/blockmgr-27b97f0f-f036-4d59-9e5e-a51ab5492316/25\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:191)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:116)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120)\n",
      "\tat org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1048)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1(DiskBlockManager.scala:372)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1$adapted(DiskBlockManager.scala:368)\n",
      "\tat scala.collection.ArrayOps$.foreach$extension(ArrayOps.scala:1324)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.doStop(DiskBlockManager.scala:368)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.stop(DiskBlockManager.scala:363)\n",
      "\tat org.apache.spark.storage.BlockManager.stop(BlockManager.scala:2166)\n",
      "\tat org.apache.spark.SparkEnv.stop(SparkEnv.scala:118)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1300)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2297)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$36(SparkContext.scala:704)\n",
      "\tat org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:231)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat scala.util.Try$.apply(Try.scala:217)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:205)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:184)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: java.io.IOException: Cannot run program \"rm\": error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1170)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1089)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:183)\n",
      "\t... 33 more\n",
      "Caused by: java.io.IOException: error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessImpl.forkAndExec(Native Method)\n",
      "\tat java.base/java.lang.ProcessImpl.<init>(ProcessImpl.java:295)\n",
      "\tat java.base/java.lang.ProcessImpl.start(ProcessImpl.java:225)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1126)\n",
      "\t... 35 more\n",
      "25/11/20 12:05:20 WARN JavaUtils: Attempt to delete using native Unix OS command failed for path = /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/spark-3a315ada-946d-469a-a8e0-c39b022b59b4/userFiles-492f5b18-6862-4c9a-931b-69a031288acd. Falling back to Java IO way\n",
      "java.io.IOException: Failed to delete: /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/spark-3a315ada-946d-469a-a8e0-c39b022b59b4/userFiles-492f5b18-6862-4c9a-931b-69a031288acd\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:191)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:116)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120)\n",
      "\tat org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1048)\n",
      "\tat org.apache.spark.SparkEnv.stop(SparkEnv.scala:131)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$stop$25(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1300)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2395)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2297)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$36(SparkContext.scala:704)\n",
      "\tat org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:231)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat scala.util.Try$.apply(Try.scala:217)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:205)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:184)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: java.io.IOException: Cannot run program \"rm\": error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1170)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1089)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:183)\n",
      "\t... 25 more\n",
      "Caused by: java.io.IOException: error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessImpl.forkAndExec(Native Method)\n",
      "\tat java.base/java.lang.ProcessImpl.<init>(ProcessImpl.java:295)\n",
      "\tat java.base/java.lang.ProcessImpl.start(ProcessImpl.java:225)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1126)\n",
      "\t... 27 more\n",
      "25/11/20 12:05:20 WARN JavaUtils: Attempt to delete using native Unix OS command failed for path = /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/spark-de2f8f38-f46c-4388-9c89-2b8d840f6039. Falling back to Java IO way\n",
      "java.io.IOException: Failed to delete: /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/spark-de2f8f38-f46c-4388-9c89-2b8d840f6039\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:191)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:116)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120)\n",
      "\tat org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1048)\n",
      "\tat org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:70)\n",
      "\tat org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:67)\n",
      "\tat scala.collection.ArrayOps$.foreach$extension(ArrayOps.scala:1324)\n",
      "\tat org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:67)\n",
      "\tat org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:231)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat scala.util.Try$.apply(Try.scala:217)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:205)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:184)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: java.io.IOException: Cannot run program \"rm\": error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1170)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1089)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:183)\n",
      "\t... 23 more\n",
      "Caused by: java.io.IOException: error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessImpl.forkAndExec(Native Method)\n",
      "\tat java.base/java.lang.ProcessImpl.<init>(ProcessImpl.java:295)\n",
      "\tat java.base/java.lang.ProcessImpl.start(ProcessImpl.java:225)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1126)\n",
      "\t... 25 more\n",
      "25/11/20 12:05:20 WARN JavaUtils: Attempt to delete using native Unix OS command failed for path = /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/spark-3a315ada-946d-469a-a8e0-c39b022b59b4. Falling back to Java IO way\n",
      "java.io.IOException: Failed to delete: /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/spark-3a315ada-946d-469a-a8e0-c39b022b59b4\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:191)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:116)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120)\n",
      "\tat org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1048)\n",
      "\tat org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:70)\n",
      "\tat org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:67)\n",
      "\tat scala.collection.ArrayOps$.foreach$extension(ArrayOps.scala:1324)\n",
      "\tat org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:67)\n",
      "\tat org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:231)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat scala.util.Try$.apply(Try.scala:217)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:205)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:184)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: java.io.IOException: Cannot run program \"rm\": error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1170)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1089)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:183)\n",
      "\t... 23 more\n",
      "Caused by: java.io.IOException: error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessImpl.forkAndExec(Native Method)\n",
      "\tat java.base/java.lang.ProcessImpl.<init>(ProcessImpl.java:295)\n",
      "\tat java.base/java.lang.ProcessImpl.start(ProcessImpl.java:225)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1126)\n",
      "\t... 25 more\n",
      "25/11/20 12:05:20 WARN JavaUtils: Attempt to delete using native Unix OS command failed for path = /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/spark-3a315ada-946d-469a-a8e0-c39b022b59b4/pyspark-993c4008-eee3-4560-bf61-99848f71e972. Falling back to Java IO way\n",
      "java.io.IOException: Failed to delete: /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/spark-3a315ada-946d-469a-a8e0-c39b022b59b4/pyspark-993c4008-eee3-4560-bf61-99848f71e972\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:191)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:116)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:138)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:124)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120)\n",
      "\tat org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1048)\n",
      "\tat org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:70)\n",
      "\tat org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:67)\n",
      "\tat scala.collection.ArrayOps$.foreach$extension(ArrayOps.scala:1324)\n",
      "\tat org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:67)\n",
      "\tat org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:231)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat scala.util.Try$.apply(Try.scala:217)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:205)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:184)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: java.io.IOException: Cannot run program \"rm\": error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1170)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1089)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:183)\n",
      "\t... 25 more\n",
      "Caused by: java.io.IOException: error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessImpl.forkAndExec(Native Method)\n",
      "\tat java.base/java.lang.ProcessImpl.<init>(ProcessImpl.java:295)\n",
      "\tat java.base/java.lang.ProcessImpl.start(ProcessImpl.java:225)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1126)\n",
      "\t... 27 more\n",
      "25/11/20 12:05:20 WARN JavaUtils: Attempt to delete using native Unix OS command failed for path = /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/spark-3a315ada-946d-469a-a8e0-c39b022b59b4/pyspark-993c4008-eee3-4560-bf61-99848f71e972. Falling back to Java IO way\n",
      "java.io.IOException: Failed to delete: /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/spark-3a315ada-946d-469a-a8e0-c39b022b59b4/pyspark-993c4008-eee3-4560-bf61-99848f71e972\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:191)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:116)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120)\n",
      "\tat org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1048)\n",
      "\tat org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:70)\n",
      "\tat org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:67)\n",
      "\tat scala.collection.ArrayOps$.foreach$extension(ArrayOps.scala:1324)\n",
      "\tat org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:67)\n",
      "\tat org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:231)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat scala.util.Try$.apply(Try.scala:217)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:205)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:184)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: java.io.IOException: Cannot run program \"rm\": error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1170)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1089)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:183)\n",
      "\t... 23 more\n",
      "Caused by: java.io.IOException: error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessImpl.forkAndExec(Native Method)\n",
      "\tat java.base/java.lang.ProcessImpl.<init>(ProcessImpl.java:295)\n",
      "\tat java.base/java.lang.ProcessImpl.start(ProcessImpl.java:225)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1126)\n",
      "\t... 25 more\n",
      "25/11/20 12:05:20 WARN JavaUtils: Attempt to delete using native Unix OS command failed for path = /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/artifacts-c9af7603-075a-403c-9014-19bb165d6081. Falling back to Java IO way\n",
      "java.io.IOException: Failed to delete: /private/var/folders/y8/5sdb2rg957jchm7dmvcshj7h0000gn/T/artifacts-c9af7603-075a-403c-9014-19bb165d6081\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:191)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:116)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:94)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively(SparkFileUtils.scala:121)\n",
      "\tat org.apache.spark.util.SparkFileUtils.deleteRecursively$(SparkFileUtils.scala:120)\n",
      "\tat org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1048)\n",
      "\tat org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:70)\n",
      "\tat org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:67)\n",
      "\tat scala.collection.ArrayOps$.foreach$extension(ArrayOps.scala:1324)\n",
      "\tat org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:67)\n",
      "\tat org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:231)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1937)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:205)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat scala.util.Try$.apply(Try.scala:217)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:205)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:184)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: java.io.IOException: Cannot run program \"rm\": error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1170)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1089)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:183)\n",
      "\t... 23 more\n",
      "Caused by: java.io.IOException: error=0, posix_spawn failed\n",
      "\tat java.base/java.lang.ProcessImpl.forkAndExec(Native Method)\n",
      "\tat java.base/java.lang.ProcessImpl.<init>(ProcessImpl.java:295)\n",
      "\tat java.base/java.lang.ProcessImpl.start(ProcessImpl.java:225)\n",
      "\tat java.base/java.lang.ProcessBuilder.start(ProcessBuilder.java:1126)\n",
      "\t... 25 more\n"
     ]
    }
   ],
   "source": [
    "# get all words\n",
    "df = df[\"value\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61c6c59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data1050",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
